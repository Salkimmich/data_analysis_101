{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbF6bOP4NaxR"
      },
      "outputs": [],
      "source": [
        "!pip install openai langchain-openai langchain-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "OPENAI_KEY=userdata.get('OPENAI_KEY')\n",
        "\n",
        "client = OpenAI(\n",
        "  api_key=OPENAI_KEY,\n",
        ")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is a LLM?\"}\n",
        "  ]\n",
        ")\n",
        "message = response.choices[0].message.content\n",
        "print(message)"
      ],
      "metadata": {
        "id": "7dbqGxHuO6yg",
        "outputId": "be072c2b-052c-4562-c111-8de5360326a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM stands for \"Large Language Model.\" It refers to a type of artificial intelligence model that is trained on vast amounts of text data to understand and generate human-like language. These models use machine learning techniques, particularly deep learning, to perform various tasks related to natural language processing (NLP), such as:\n",
            "\n",
            "1. **Text generation**: Creating coherent and contextually relevant text based on prompts.\n",
            "2. **Text completion**: Predicting and filling in the next words or sentences in a given passage.\n",
            "3. **Translation**: Converting text from one language to another.\n",
            "4. **Question answering**: Providing answers to questions based on a given context or general knowledge.\n",
            "5. **Summarization**: Condensing long articles or documents into shorter summaries while retaining key information.\n",
            "6. **Text classification**: Categorizing text into predefined categories.\n",
            "\n",
            "LLMs, like OpenAI's GPT series (including GPT-3 and GPT-4), have gained significant attention due to their remarkable ability to generate human-like text and handle a wide array of language-related tasks with high accuracy. The \"large\" in LLM refers to the scale of the model, which typically has billions of parameters, allowing it to capture complex patterns in language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a data generator for restaurant reviews.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Generate a positive review about a pasta dish and an ok environment\"}\n",
        "  ]\n",
        ")\n",
        "message = response.choices[0].message.content\n",
        "print(message)"
      ],
      "metadata": {
        "id": "sK4irJKUP9pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(api_key=OPENAI_KEY)\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a data generator for restaurant reviews.\"),\n",
        "    (\"user\", \"Generate a positive review about a pasta dish and an ok environment\")\n",
        "])"
      ],
      "metadata": {
        "id": "AUTtDR2PTZWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
        "\n",
        "HF_TOKEN=userdata.get('HF_TOKEN')\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.03,\n",
        "    huggingfacehub_api_token=HF_TOKEN  # Use your token here\n",
        ")\n",
        "\n",
        "chat = ChatHuggingFace(llm=llm, verbose=True)\n",
        "messages = [\n",
        "    (\"system\", \"You are a helpful translator. Translate the user sentence to French.\"),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "\n",
        "chat.invoke(messages)"
      ],
      "metadata": {
        "id": "ox7t1pS_Q8TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rate response\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a restaurant reviewer. I want you to give a 1-5 rating based on a review.\"},\n",
        "    {\"role\": \"user\", \"content\": \"The food was average. We had good company fortunately. Food was not good. Only give the rating and nothing else.\"}\n",
        "  ]\n",
        ")\n",
        "message = response.choices[0].message.content\n",
        "print(message)"
      ],
      "metadata": {
        "id": "0rCs-0GWRAoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract information\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are an information extraction system. I want you to extract people and organisations.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Google released earnings and Sundar Pichai was not happy. Use json.\"}\n",
        "  ]\n",
        ")\n",
        "message = response.choices[0].message.content\n",
        "print(message)"
      ],
      "metadata": {
        "id": "-dnjR7sDRMZN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}